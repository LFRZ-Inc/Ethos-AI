#!/usr/bin/env python3
"""
Ethos AI - Client-Side Storage Version
This version provides APIs for client-side storage of device memory
No server-side storage - everything stays on user devices
"""

import json
import hashlib
from datetime import datetime
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List

app = FastAPI(title="Ethos AI - Client Storage", version="5.1.0-CLIENT-STORAGE")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API Models for client-side storage
class ClientMemoryRequest(BaseModel):
    device_id: str
    conversations: List[Dict] = []
    settings: Dict = {}

class ClientMemoryResponse(BaseModel):
    device_id: str
    conversations: List[Dict]
    settings: Dict
    total_conversations: int
    storage_size_kb: float

class ChatWithMemoryRequest(BaseModel):
    message: str
    device_id: str
    device_memory: Optional[List[Dict]] = None  # Client sends their memory
    model_override: Optional[str] = None

class ChatWithMemoryResponse(BaseModel):
    response: str
    model: str
    device_id: str
    updated_memory: List[Dict]  # Server returns updated memory
    context_used: bool
    storage_size_kb: float

# Client-side storage endpoints
@app.post("/api/client/memory/save", response_model=ClientMemoryResponse)
async def save_client_memory(request: ClientMemoryRequest):
    """Client saves their memory to server (temporary, for processing)"""
    try:
        # Calculate storage size
        memory_json = json.dumps(request.conversations)
        storage_size_kb = len(memory_json.encode('utf-8')) / 1024
        
        return ClientMemoryResponse(
            device_id=request.device_id,
            conversations=request.conversations,
            settings=request.settings,
            total_conversations=len(request.conversations),
            storage_size_kb=storage_size_kb
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/client/chat", response_model=ChatWithMemoryResponse)
async def chat_with_client_memory(request: ChatWithMemoryRequest):
    """Chat endpoint that works with client-side memory"""
    try:
        # Process client memory to build context
        device_context = []
        if request.device_memory:
            for conv in request.device_memory[-10:]:  # Last 10 conversations
                if 'message' in conv and 'response' in conv:
                    device_context.append({
                        "role": "user",
                        "content": conv['message']
                    })
                    device_context.append({
                        "role": "assistant", 
                        "content": conv['response']
                    })
        
        # Generate response (simplified - you'd integrate with your AI models)
        response = f"Hello! I can see you have {len(device_context)//2} previous conversations. "
        response += "This response would be generated by your AI models with context awareness."
        
        # Create updated memory for client
        new_conversation = {
            "id": f"conv_{int(datetime.now().timestamp())}",
            "timestamp": datetime.now().isoformat(),
            "message": request.message,
            "response": response,
            "model": request.model_override or "ethos-phi"
        }
        
        updated_memory = request.device_memory or []
        updated_memory.append(new_conversation)
        
        # Keep only last 50 conversations
        if len(updated_memory) > 50:
            updated_memory = updated_memory[-50:]
        
        # Calculate storage size
        memory_json = json.dumps(updated_memory)
        storage_size_kb = len(memory_json.encode('utf-8')) / 1024
        
        return ChatWithMemoryResponse(
            response=response,
            model=request.model_override or "ethos-phi",
            device_id=request.device_id,
            updated_memory=updated_memory,
            context_used=len(device_context) > 0,
            storage_size_kb=storage_size_kb
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/client/storage/info")
async def get_storage_info():
    """Get information about client-side storage requirements"""
    return {
        "storage_type": "client_side",
        "recommended_storage": {
            "browser_localStorage": "5-10 MB per device",
            "mobile_app": "10-50 MB per device",
            "desktop_app": "10-100 MB per device"
        },
        "conversation_size": "1-5 KB per conversation",
        "max_conversations": "50 per device (recommended)",
        "total_storage_per_device": "50-250 KB typical usage",
        "benefits": [
            "No server storage required",
            "Complete privacy - data stays on device",
            "Works offline",
            "No database needed"
        ],
        "implementation": {
            "browser": "localStorage.setItem('ethos_memory', JSON.stringify(memory))",
            "mobile": "AsyncStorage.setItem('ethos_memory', JSON.stringify(memory))",
            "desktop": "File system or local database"
        }
    }

@app.get("/")
async def root():
    return {
        "message": "Ethos AI - Client-Side Storage Version",
        "version": "5.1.0-CLIENT-STORAGE",
        "storage": "client_side_only",
        "features": [
            "No server storage",
            "Client manages their own memory",
            "Privacy-first approach",
            "Offline capability"
        ]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
